{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fcb47c-6572-4d99-a71a-0dc99c57972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb160ba-9d19-4687-aec4-e467c31dc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08d8e76-dbaa-43ea-97da-7fb90fb77c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_ann, read_report, format_doc_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce1c1d09-a212-401e-87a1-bf470673dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'chifir-cytology-and-histopathology-invasive-fungal-infection-reports-1.0.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db8c14f-efb1-4016-8fdc-7239f2e23001",
   "metadata": {},
   "source": [
    "# 1. Digest reports and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910686ce-ba47-4321-aa31-f8b7b3656fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ann_dir = os.path.join(DATA_DIR, 'annotations/')\n",
    "root_txt_dir = os.path.join(DATA_DIR, 'reports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d324064-3207-4ca8-9e0a-a1cb8ef10807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all entities\n",
    "\n",
    "all_ann_files = [f for f in os.listdir(root_ann_dir) if f.endswith('ann')]\n",
    "\n",
    "all_ents = []\n",
    "for ann_f in all_ann_files:\n",
    "    try:\n",
    "        ents = read_ann(os.path.join(root_ann_dir, ann_f))\n",
    "    except:\n",
    "        print(ann_f)\n",
    "    all_ents.extend(ents)\n",
    "len(all_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a33abf-dcbe-4a5a-a6fd-e5520e54dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClinicalQuery',\n",
       " 'FungalDescriptor',\n",
       " 'Fungus',\n",
       " 'Invasiveness',\n",
       " 'SampleType',\n",
       " 'Stain',\n",
       " 'equivocal',\n",
       " 'negative',\n",
       " 'positive'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_types = [t for (_,_,_,t) in all_ents]\n",
    "\n",
    "set(ent_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f4f2-5c72-4592-b50e-d206ebf1a22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aeb5a75-48ff-4033-ad72-57ef5cd63e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt57_r1\n"
     ]
    }
   ],
   "source": [
    "# combine report and ann files for every pt to get the right format for bert\n",
    "all_pt = [f.strip('.ann') for f in os.listdir(root_ann_dir) if f.endswith('ann')]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for pt in all_pt:\n",
    "    note = read_report(os.path.join(DATA_DIR, f'reports/{pt}.txt'))\n",
    "    ents = read_ann(os.path.join(DATA_DIR, f'annotations/{pt}.ann'))\n",
    "\n",
    "    doc = nlp(note)\n",
    "\n",
    "    try:\n",
    "        lines, tags = format_doc_and_labels(doc, ents, remove_shorts=3)\n",
    "\n",
    "        assert len(lines) == len(tags)\n",
    "        for i, (token, tag) in enumerate(zip(lines, tags)):\n",
    "            all_data.append({\n",
    "                'id': f'{pt}_{i}',\n",
    "                'tokens': token,\n",
    "                'tags': tag\n",
    "            })\n",
    "            \n",
    "    except:\n",
    "        print(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a77915b-e947-43da-96fa-35f5eabef3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of BIO tags\n",
    "all_tags = []\n",
    "for d in all_data:\n",
    "    all_tags.extend(d['tags'])\n",
    "all_tags = sorted(list(set(all_tags)))\n",
    "len(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc91d21-57ce-4ae9-b149-1409a808434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notseen not see\n",
      "927 934\n",
      "** pt57_r1 **\n",
      "GMS  GM\n",
      "938 941\n",
      "** pt57_r1 **\n",
      "Fungi  Fung\n",
      "1280 1285\n",
      "** pt57_r1 **\n",
      "Pneumocystis /Pneumocysti\n",
      "1286 1298\n",
      "** pt57_r1 **\n",
      "not seen  not see\n",
      "1303 1311\n",
      "** pt57_r1 **\n",
      "GMS  GM\n",
      "1315 1318\n",
      "** pt57_r1 **\n"
     ]
    }
   ],
   "source": [
    "# pt57_r1 is a special case w/ some data error starting from T8 (offset by 1 char; fix T8 string)\n",
    "from utils import process_note_ent_pair\n",
    "\n",
    "pt = 'pt57_r1'\n",
    "\n",
    "note = read_report(os.path.join(DATA_DIR, f'reports/{pt}.txt'))\n",
    "ents = read_ann(os.path.join(DATA_DIR, f'annotations/{pt}.ann'))\n",
    "\n",
    "d = process_note_ent_pair(note, ents, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5e693e-74d4-4534-a473-447fb62f416b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GMS', ' GM')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note[1316:1319], note[1315:1318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02007eb2-7ba1-4549-8426-b54835dc88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually fixed pt57_r1 in the new folder `annotations-fixed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999eca5c-f9b8-4279-ac9e-73f053c8ea9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a069fd0-8e2f-4361-885c-de80282a4aa8",
   "metadata": {},
   "source": [
    "# 2. Get train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa76a1a-ce13-4397-9974-fbd90b6490d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS = [\n",
    "    'B-ClinicalQuery',\n",
    "    'I-ClinicalQuery',\n",
    "    'B-FungalDescriptor',\n",
    "    'I-FungalDescriptor',\n",
    "    'B-Fungus',\n",
    "    'I-Fungus',\n",
    "    'B-Invasiveness',\n",
    "    'I-Invasiveness',\n",
    "    'B-SampleType',\n",
    "    'I-SampleType',\n",
    "    'B-Stain',\n",
    "    'I-Stain',\n",
    "    'B-equivocal', # didn't find I-equivocal\n",
    "    'B-negative',\n",
    "    'I-negative',\n",
    "    'B-positive',\n",
    "    'I-positive',\n",
    "    'O',\n",
    "]\n",
    "\n",
    "tag2id = {t:i for i, t in enumerate(TAGS)}\n",
    "len(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcd1dac-7150-4cea-bc78-ca2d9b0578ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import Features, Sequence, Value, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9505bd3d-995c-468b-9979-5302615030e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pt = [f.strip('.ann') for f in os.listdir(root_ann_dir) if f.endswith('ann')]\n",
    "\n",
    "def encode_tags(example):\n",
    "    example['ner_tags'] = [tag2id[tag] for tag in example['tags']]\n",
    "    return example\n",
    "    \n",
    "def get_pt_data(pts, reports_path=root_txt_dir, annotations_path=root_ann_dir):\n",
    "\n",
    "    all_data = []\n",
    "    \n",
    "    for pt in pts:\n",
    "        note = read_report(os.path.join(reports_path, f'{pt}.txt'))\n",
    "        ents = read_ann(os.path.join(annotations_path, f'{pt}.ann'))\n",
    "    \n",
    "        doc = nlp(note)\n",
    "    \n",
    "        try:\n",
    "            lines, tags = format_doc_and_labels(doc, ents, remove_shorts=3)\n",
    "    \n",
    "            assert len(lines) == len(tags)\n",
    "            for i, (token, tag) in enumerate(zip(lines, tags)):\n",
    "                all_data.append({\n",
    "                    'id': f'{pt}_{i}',\n",
    "                    'tokens': token,\n",
    "                    'ner_tags': tag\n",
    "                })\n",
    "                \n",
    "        except:\n",
    "            print(pt)\n",
    "\n",
    "    features = Features({\n",
    "        'id': Value('string'),\n",
    "        'tokens': Sequence(Value('string')),\n",
    "        'ner_tags': Sequence(ClassLabel(names=TAGS))\n",
    "    })\n",
    "\n",
    "    dset = datasets.Dataset.from_list(all_data, features=features)\n",
    "    \n",
    "    # dset = dset.map(encode_tags, remove_columns=['tags'])\n",
    "\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993c5306-07df-4b92-8e99-4c814b415d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>histopathology_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>report_no</th>\n",
       "      <th>y_report</th>\n",
       "      <th>dataset</th>\n",
       "      <th>val_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>development</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>development</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>development</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>325</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>development</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>559</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>development</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   histopathology_id  patient_id  report_no  y_report      dataset  val_fold\n",
       "0                658          13          1  Positive  development      10.0\n",
       "1                189          14          1  Positive  development       7.0\n",
       "2                529          28          1  Negative  development       8.0\n",
       "3                325          28          2  Positive  development       8.0\n",
       "4                559          28          3  Negative  development       8.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf = pd.read_csv('./chifir_metadata.csv')\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a3ae1b9-3936-47f8-ac22-60c6fd95b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metadata matches reports/anns\n",
    "for p, r in zip(mdf.patient_id, mdf.report_no):\n",
    "    assert f'pt{p}_r{r}' in all_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10cae6c1-daaf-4c67-917b-7149a633a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for three splits\n",
    "\n",
    "train_pt = []\n",
    "val_pt = []\n",
    "test_pt = []\n",
    "\n",
    "# use val fold 1, 2 as validation to tune hparam\n",
    "msk1 = mdf.dataset == 'development'\n",
    "msk2 = mdf.val_fold.isin([1.,2.])\n",
    "\n",
    "for _, row in mdf[msk1 & ~msk2].iterrows():\n",
    "    train_pt.append(f\"pt{row['patient_id']}_r{row['report_no']}\")\n",
    "\n",
    "for _, row in mdf[msk1 & msk2].iterrows():\n",
    "    val_pt.append(f\"pt{row['patient_id']}_r{row['report_no']}\")\n",
    "\n",
    "for _, row in mdf[mdf.dataset == 'test'].iterrows():\n",
    "    test_pt.append(f\"pt{row['patient_id']}_r{row['report_no']}\")\n",
    "\n",
    "assert len(train_pt) + len(val_pt) + len(test_pt) == len(all_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e1464c-38d0-4746-a68d-a022a4fda9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the report w/ error appears in test set\n",
    "'pt57_r1' in test_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf7cadd5-f546-4ad5-aeaf-1af82a1e860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = get_pt_data(train_pt)\n",
    "ds_val = get_pt_data(val_pt)\n",
    "ds_test = get_pt_data(test_pt, annotations_path=os.path.join(DATA_DIR, 'annotations-fixed/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f8f54c-68b6-4ce2-b35b-7f5c5e031e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955bc698bc7544a08dc9e91c22f71098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd43ec6afeb043e28f1677995a2d1c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434c0fba0c6a470b96dbc0b5f8d5c992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1049 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': ds_train,\n",
    "        'validation': ds_val,\n",
    "        'test': ds_test,\n",
    "    })\n",
    "\n",
    "raw_datasets.save_to_disk('chifir_hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6dc44-9dfd-4b73-bec2-5491624c0b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
