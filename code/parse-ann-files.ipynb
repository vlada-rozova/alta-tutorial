{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd93442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils import get_filename, read_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b417d8",
   "metadata": {},
   "source": [
    "___\n",
    "# Extract gold standard annotations\n",
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d049816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(283, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>report_no</th>\n",
       "      <th>y_report</th>\n",
       "      <th>histopathology_id</th>\n",
       "      <th>val_fold</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>658</td>\n",
       "      <td>10.0</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>189</td>\n",
       "      <td>7.0</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>529</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>325</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>559</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  report_no  y_report  histopathology_id  val_fold      dataset\n",
       "0          13          1  Positive                658      10.0  development\n",
       "1          14          1  Positive                189       7.0  development\n",
       "2          28          1  Negative                529       8.0  development\n",
       "3          28          2  Positive                325       8.0  development\n",
       "4          28          3  Negative                559       8.0  development"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "path = \"../../../Data/CHIFIR/\"\n",
    "\n",
    "# Metadata\n",
    "df = pd.read_csv(path + \"chifir_metadata.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a920bf",
   "metadata": {},
   "source": [
    "### Parse annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a4b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1137 concepts and 606 relations.\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes to store annotations\n",
    "concepts = pd.DataFrame(columns=['histopathology_id', 'patient_id', 'report_no', \n",
    "                                 'concept_id', 'concept', 'phrase', 'position', 'start_char', 'end_char'])\n",
    "relations = pd.DataFrame(columns=['histopathology_id', 'patient_id', 'report_no', \n",
    "                                  'relation_id', 'relation', 'arg1', 'arg2'])\n",
    "\n",
    "for _, x in df.iterrows():\n",
    "    # Define filename\n",
    "    filename = get_filename(x.patient_id, x.report_no, file_format='ann')\n",
    "    \n",
    "    # Open and read annotation file\n",
    "    with open(path + \"annotations/\" + filename, 'r') as f:\n",
    "        annotation = f.readlines()\n",
    "        \n",
    "    if annotation:    \n",
    "        # Loop over each line of the annotation file\n",
    "        for line in annotation:\n",
    "\n",
    "            # Concept\n",
    "            if re.match(\"T\", line):\n",
    "\n",
    "                # Create an entry containing concept ID, category, position and the raw text\n",
    "                substrings = line.strip().split('\\t')\n",
    "                concept_id = substrings[0]\n",
    "                concept = substrings[1].split(maxsplit=1)[0]\n",
    "                position = substrings[1].split(maxsplit=1)[1]\n",
    "                start_char, end_char = re.split(' |;', position)[-2:]\n",
    "                text = substrings[2]\n",
    "\n",
    "                tmp = pd.DataFrame({\n",
    "                    'histopathology_id': x.histopathology_id,\n",
    "                    'patient_id': x.patient_id, \n",
    "                    'report_no': x.report_no, \n",
    "                    'concept_id': concept_id, \n",
    "                    'concept': concept, \n",
    "                    'phrase': text,\n",
    "                    'position': position, \n",
    "                    'start_char': int(start_char),\n",
    "                    'end_char': int(end_char),\n",
    "                }, index=[0])\n",
    "\n",
    "                # Add to the table of concepts\n",
    "                concepts = pd.concat([concepts, tmp], axis=0, ignore_index=True)\n",
    "\n",
    "            # Relation\n",
    "            elif re.match(\"R\", line):\n",
    "\n",
    "                # Create an entry containing relation ID, type and IDs of the arguments\n",
    "                substrings = line.strip().split()\n",
    "                relation_id = substrings[0]\n",
    "                relation = substrings[1]\n",
    "                arg1 = substrings[2].split(':')[1]\n",
    "                arg2 = substrings[3].split(':')[1]\n",
    "\n",
    "                tmp = pd.DataFrame({\n",
    "                    'histopathology_id': x.histopathology_id,\n",
    "                    'patient_id': x.patient_id, \n",
    "                    'report_no': x.report_no, \n",
    "                    'relation_id': relation_id, \n",
    "                    'relation': relation, \n",
    "                    'arg1': arg1, \n",
    "                    'arg2': arg2\n",
    "                }, index=[0])\n",
    "\n",
    "                # Add to the table of relations\n",
    "                relations = pd.concat([relations, tmp], axis=0, ignore_index=True)\n",
    "                \n",
    "# Convert patient ID and report number to int\n",
    "concepts[['patient_id', 'report_no']] = concepts[['patient_id', 'report_no']].astype(int)\n",
    "relations[['patient_id', 'report_no']] = relations[['patient_id', 'report_no']].astype(int)\n",
    "\n",
    "print(\"Extracted %d concepts and %d relations.\" % (concepts.shape[0], relations.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2360cbd",
   "metadata": {},
   "source": [
    "### Separate discontinuous concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f49b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discont concepts have ;-separated positions\n",
    "idx = concepts[concepts.position.str.contains(\";\")].index\n",
    "\n",
    "# Split discont concepts into a separate dataframe\n",
    "discont = concepts.iloc[idx].copy()\n",
    "concepts.drop(idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3486a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over discont concepts extracting individual spans\n",
    "for _,x in discont.iterrows():\n",
    "    spans = []\n",
    "    i = 0\n",
    "    for pos in x.position.split(';'):\n",
    "        # Extract start and end char positions\n",
    "        start_char, end_char = map(int, pos.split())\n",
    "        # Calculate span length\n",
    "        len_span = end_char - start_char\n",
    "        # Extract span text\n",
    "        phrase = x.phrase[i:i+len_span]\n",
    "        # Add to list of spans\n",
    "        spans.append((start_char, end_char, phrase))\n",
    "        i = i + len_span + 1\n",
    "        \n",
    "    # Sort extracted spans by starting position\n",
    "    spans = sorted(spans, key=lambda x: x[0])\n",
    "    \n",
    "    # Append extracted spans to the dataframe with gold standard concepts \n",
    "    for span in spans:\n",
    "        tmp = x.copy()\n",
    "        tmp['start_char'] = span[0]\n",
    "        tmp['end_char'] = span[1]\n",
    "        tmp['phrase'] = span[2]\n",
    "        concepts = pd.concat([concepts, tmp.to_frame().T], axis=0, ignore_index=True)\n",
    "        \n",
    "# Remove position column\n",
    "concepts.drop('position', axis=1, inplace=True)\n",
    "concepts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924bff2",
   "metadata": {},
   "source": [
    "### Preceding and following termsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7e0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_termset(x):\n",
    "    arg2_ids = relations[(relations.histopathology_id==x.histopathology_id) & \n",
    "                     (relations.arg1==x.concept_id)\n",
    "                    ].arg2\n",
    "    arg2_start_char = concepts[(concepts.histopathology_id==x.histopathology_id) & \n",
    "                                concepts.concept_id.isin(arg2_ids)\n",
    "                               ].start_char\n",
    "    return (x.start_char < arg2_start_char).any(), (x.start_char > arg2_start_char).any()\n",
    "\n",
    "# Only check order for positive and negative cue\n",
    "cues = concepts[concepts.concept.isin(['positive', 'negative'])]\n",
    "\n",
    "# Determine if a cue is preceding and/or following\n",
    "concepts[['preceding', 'following']] = pd.DataFrame(cues.apply(assign_termset, axis=1).tolist(), \n",
    "                                                    index=cues.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81eb8a",
   "metadata": {},
   "source": [
    "### Save the extracted concepts and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d40af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts.to_csv(\"../datasets/gold_concepts.csv\", index=False)\n",
    "relations.to_csv(\"../datasets/gold_relations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3c1d7",
   "metadata": {},
   "source": [
    "### Create composite concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c56c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totalling 1497 concepts and composite concepts.\n"
     ]
    }
   ],
   "source": [
    "def add_composite_concepts(concepts, relation, composite_name):\n",
    "    \n",
    "    # Loop over the dataframe with extracted relations\n",
    "    for _, x in relations[relations.relation==relation].iterrows():\n",
    "        \n",
    "        # Define the next vacant concept ID\n",
    "        next_id = concepts[concepts.histopathology_id==x.histopathology_id].concept_id.apply(lambda x: \n",
    "                                                                                             int(x[1:])\n",
    "                                                                                            ).max() + 1\n",
    "        \n",
    "        # Determine the object (Arg2) of a relation\n",
    "        y = concepts[(concepts.histopathology_id==x.histopathology_id) & \n",
    "                     (concepts.concept_id==x.arg2)].iloc[0]\n",
    "        \n",
    "        # Create an entry containing concept ID, composite category, position and the raw text\n",
    "        tmp = pd.DataFrame({\n",
    "            'histopathology_id': x.histopathology_id,\n",
    "            'patient_id': x.patient_id,\n",
    "            'report_no': x.report_no, \n",
    "            'concept_id': 'T' + str(next_id), \n",
    "            'concept': composite_name + y.concept,\n",
    "            'phrase': y.phrase,\n",
    "            'start_char': y.start_char,\n",
    "            'end_char': y.end_char,\n",
    "        }, index=[0])\n",
    "        \n",
    "        # Add to the table of concepts\n",
    "        concepts = pd.concat([concepts, tmp], axis=0, ignore_index=True)\n",
    "        \n",
    "    return concepts\n",
    "\n",
    "# Add the argument of a positive relation to the table of concepts as an \"affirmed\" concept\n",
    "concepts = add_composite_concepts(concepts, 'positive-rel', 'affirmed')\n",
    "\n",
    "# Add the argument of a negative relation to the table of concepts as a \"negated\" concept\n",
    "concepts = add_composite_concepts(concepts, 'negative-rel', 'negated')\n",
    "\n",
    "# Drop duplicated composite concepts\n",
    "concepts.drop_duplicates(subset=['histopathology_id', 'concept', 'start_char'], inplace=True, ignore_index=True)\n",
    "\n",
    "print(\"Totalling %d concepts and composite concepts.\" % concepts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2cce556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>histopathology_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>report_no</th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept</th>\n",
       "      <th>phrase</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>preceding</th>\n",
       "      <th>following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>Invasiveness</td>\n",
       "      <td>intravascular spaces</td>\n",
       "      <td>669</td>\n",
       "      <td>689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>T4</td>\n",
       "      <td>Stain</td>\n",
       "      <td>PAS</td>\n",
       "      <td>715</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>T5</td>\n",
       "      <td>Stain</td>\n",
       "      <td>GMS</td>\n",
       "      <td>723</td>\n",
       "      <td>726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>T9</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>700</td>\n",
       "      <td>708</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>T3</td>\n",
       "      <td>FungalDescriptor</td>\n",
       "      <td>necrotic fungi</td>\n",
       "      <td>651</td>\n",
       "      <td>665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>884</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>T10</td>\n",
       "      <td>negatedFungalDescriptor</td>\n",
       "      <td>fungal elements</td>\n",
       "      <td>583</td>\n",
       "      <td>598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>884</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>T11</td>\n",
       "      <td>negatedFungalDescriptor</td>\n",
       "      <td>fungal elements</td>\n",
       "      <td>1073</td>\n",
       "      <td>1088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>884</td>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>T12</td>\n",
       "      <td>negatedFungalDescriptor</td>\n",
       "      <td>fungal elements</td>\n",
       "      <td>1564</td>\n",
       "      <td>1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>729</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>T5</td>\n",
       "      <td>negatedFungalDescriptor</td>\n",
       "      <td>fungi</td>\n",
       "      <td>1034</td>\n",
       "      <td>1039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>729</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>T6</td>\n",
       "      <td>negatedFungus</td>\n",
       "      <td>Pneumocystis</td>\n",
       "      <td>1043</td>\n",
       "      <td>1055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1497 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     histopathology_id patient_id report_no concept_id  \\\n",
       "0                  658         13         1         T2   \n",
       "1                  658         13         1         T4   \n",
       "2                  658         13         1         T5   \n",
       "3                  658         13         1         T9   \n",
       "4                  658         13         1         T3   \n",
       "...                ...        ...       ...        ...   \n",
       "1492               884        176         2        T10   \n",
       "1493               884        176         2        T11   \n",
       "1494               884        176         2        T12   \n",
       "1495               729        219         2         T5   \n",
       "1496               729        219         2         T6   \n",
       "\n",
       "                      concept                phrase start_char end_char  \\\n",
       "0                Invasiveness  intravascular spaces        669      689   \n",
       "1                       Stain                   PAS        715      718   \n",
       "2                       Stain                   GMS        723      726   \n",
       "3                    positive              positive        700      708   \n",
       "4            FungalDescriptor        necrotic fungi        651      665   \n",
       "...                       ...                   ...        ...      ...   \n",
       "1492  negatedFungalDescriptor       fungal elements        583      598   \n",
       "1493  negatedFungalDescriptor       fungal elements       1073     1088   \n",
       "1494  negatedFungalDescriptor       fungal elements       1564     1579   \n",
       "1495  negatedFungalDescriptor                 fungi       1034     1039   \n",
       "1496            negatedFungus          Pneumocystis       1043     1055   \n",
       "\n",
       "     preceding following  \n",
       "0          NaN       NaN  \n",
       "1          NaN       NaN  \n",
       "2          NaN       NaN  \n",
       "3        False      True  \n",
       "4          NaN       NaN  \n",
       "...        ...       ...  \n",
       "1492       NaN       NaN  \n",
       "1493       NaN       NaN  \n",
       "1494       NaN       NaN  \n",
       "1495       NaN       NaN  \n",
       "1496       NaN       NaN  \n",
       "\n",
       "[1497 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a3d64",
   "metadata": {},
   "source": [
    "### Save the extracted annotatons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319442b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts.to_csv(\"../datasets/gold_composite.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcfaea",
   "metadata": {},
   "source": [
    "___\n",
    "# Prepare datasets\n",
    "### Load reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e50db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_results'] = df.apply(read_report, path=path + \"reports/\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2852041",
   "metadata": {},
   "source": [
    "### Convert report labels to `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = np.where(df.y_report==\"Positive\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1810d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "df[df.dataset=='development'].to_csv(\"../datasets/reports_dev.csv\", index=False)\n",
    "df[df.dataset=='test'].to_csv(\"../datasets/reports_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76785b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
