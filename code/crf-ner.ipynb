{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea42d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import *\n",
    "\n",
    "import evalutils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fee221",
   "metadata": {},
   "source": [
    "___\n",
    "# Gold standard annotations\n",
    "### Load gold standard concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cffdcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>histopathology_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>report_no</th>\n",
       "      <th>concept</th>\n",
       "      <th>phrase</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Invasiveness</td>\n",
       "      <td>intravascular spaces</td>\n",
       "      <td>669</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Stain</td>\n",
       "      <td>PAS</td>\n",
       "      <td>715</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Stain</td>\n",
       "      <td>GMS</td>\n",
       "      <td>723</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>700</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>FungalDescriptor</td>\n",
       "      <td>necrotic fungi</td>\n",
       "      <td>651</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   histopathology_id  patient_id  report_no           concept  \\\n",
       "0                658          13          1      Invasiveness   \n",
       "1                658          13          1             Stain   \n",
       "2                658          13          1             Stain   \n",
       "3                658          13          1          positive   \n",
       "4                658          13          1  FungalDescriptor   \n",
       "\n",
       "                 phrase  start_char  end_char  \n",
       "0  intravascular spaces         669       689  \n",
       "1                   PAS         715       718  \n",
       "2                   GMS         723       726  \n",
       "3              positive         700       708  \n",
       "4        necrotic fungi         651       665  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gold standard concepts\n",
    "true_concepts = pd.read_csv(\"../datasets/gold_concepts.csv\")\n",
    "true_concepts.drop(['concept_id','preceding', 'following'], axis=1, inplace=True)\n",
    "print(true_concepts.shape)\n",
    "true_concepts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd95e87",
   "metadata": {},
   "source": [
    "### Load tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69943485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model with disable NER\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=['ner'])\n",
    "\n",
    "# Apply tokeniser to gold standard annotations\n",
    "true_concepts['doc'] = true_concepts.phrase.apply(nlp.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e7075",
   "metadata": {},
   "source": [
    "### Assign BIOES tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69eb992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store concepts with BIOES tags\n",
    "true_concepts_bioes = pd.DataFrame(columns=true_concepts.columns)\n",
    "\n",
    "# Single-token entities\n",
    "true_concepts_bioes = true_concepts[true_concepts.doc.apply(len) == 1].copy()\n",
    "\n",
    "# Add the \"S\" tag\n",
    "true_concepts_bioes.concept = true_concepts_bioes.concept.apply(lambda x: \"S-\" + x)\n",
    "\n",
    "# Remove doc\n",
    "true_concepts_bioes.drop('doc', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f14640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-token entities\n",
    "for _,x in true_concepts[true_concepts.doc.apply(len) > 1].iterrows():\n",
    "    \n",
    "    # Loop over tokens\n",
    "    for token in x.doc:\n",
    "        \n",
    "        # Skip if whitespace\n",
    "        if token.is_space:\n",
    "            continue\n",
    "        \n",
    "        # If the first token tag with \"B-\"\n",
    "        if token.i==0:\n",
    "            concept = \"B-\" + x.concept\n",
    "            \n",
    "        # If the last token tag with \"E-\"\n",
    "        elif token.i+1==len(x.doc):\n",
    "            concept = \"E-\" + x.concept\n",
    "            \n",
    "        # If in the middle tag with \"I-\"\n",
    "        else:\n",
    "            concept = \"I-\" + x.concept\n",
    "\n",
    "        # Adjust start char position\n",
    "        start_char = x.start_char + token.idx \n",
    "\n",
    "        tmp = pd.DataFrame({\n",
    "            'histopathology_id': x.histopathology_id,\n",
    "            'patient_id': x.patient_id, \n",
    "            'report_no': x.report_no, \n",
    "            'concept': concept, \n",
    "            'phrase': token,\n",
    "            'start_char': start_char,\n",
    "            'end_char': start_char + len(token),\n",
    "        }, index=[0])\n",
    "\n",
    "        # Add to the table of concepts\n",
    "        true_concepts_bioes = pd.concat([true_concepts_bioes, tmp], axis=0, ignore_index=True) \n",
    "        \n",
    "# Sort BIOES tagged concepts\n",
    "true_concepts_bioes.sort_values(by=['histopathology_id', 'start_char'], inplace=True)\n",
    "true_concepts_bioes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd2b12",
   "metadata": {},
   "source": [
    "___\n",
    "# Prepare data\n",
    "### Load reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201da83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>report_no</th>\n",
       "      <th>y_report</th>\n",
       "      <th>histopathology_id</th>\n",
       "      <th>val_fold</th>\n",
       "      <th>dataset</th>\n",
       "      <th>order_results</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>658</td>\n",
       "      <td>10.0</td>\n",
       "      <td>development</td>\n",
       "      <td>\"XXXXXX M XXXXXXXXXX  Report (XXXXXXXX)\\nCLINI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>189</td>\n",
       "      <td>7.0</td>\n",
       "      <td>development</td>\n",
       "      <td>\"URNO     XXXXXXXX \\nLab No    XXXXXXXXX      ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>529</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "      <td>\"URNO         XXXXXXXXX Lab No    XXXXXXXXX   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>325</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "      <td>\"URNO     XXXXXXXXX \\nLab No    XXXXXXXXX     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>559</td>\n",
       "      <td>8.0</td>\n",
       "      <td>development</td>\n",
       "      <td>\"URNO     XXXXXXXXX \\nLab No    XXXXXXXXX     ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  report_no  y_report  histopathology_id  val_fold      dataset  \\\n",
       "0          13          1  Positive                658      10.0  development   \n",
       "1          14          1  Positive                189       7.0  development   \n",
       "2          28          1  Negative                529       8.0  development   \n",
       "3          28          2  Positive                325       8.0  development   \n",
       "4          28          3  Negative                559       8.0  development   \n",
       "\n",
       "                                       order_results  y  \n",
       "0  \"XXXXXX M XXXXXXXXXX  Report (XXXXXXXX)\\nCLINI...  1  \n",
       "1  \"URNO     XXXXXXXX \\nLab No    XXXXXXXXX      ...  1  \n",
       "2  \"URNO         XXXXXXXXX Lab No    XXXXXXXXX   ...  0  \n",
       "3  \"URNO     XXXXXXXXX \\nLab No    XXXXXXXXX     ...  1  \n",
       "4  \"URNO     XXXXXXXXX \\nLab No    XXXXXXXXX     ...  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the development set of reports\n",
    "df = pd.read_csv(\"../datasets/reports_dev.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0040de6",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5fd468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spacy model with disable NER\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=['ner'])\n",
    "\n",
    "# Enable sentensizer\n",
    "nlp.enable_pipe('senter')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38450244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the NLP pipe   line\n",
    "df['doc'] = df.order_results.apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b35d1",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ee5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(doc, i):\n",
    "    \"\"\"\n",
    "    Extract the previous and following tokens ignoring whitespaces.\n",
    "    \"\"\"\n",
    "    if (i==0) or (i==1 and doc[i-1].is_space):\n",
    "        prev_token = \"\"\n",
    "    else:\n",
    "        prev_token = doc[i-2].text if doc[i-1].is_space else doc[i-1].text\n",
    "        \n",
    "    if (i==len(doc)-1) or (i==len(doc)-2 and doc[-1].is_space):\n",
    "        next_token = \"\"\n",
    "    else:\n",
    "        next_token = doc[i+2].text if doc[i+1].is_space else doc[i+1].text\n",
    "    \n",
    "    return prev_token, next_token\n",
    "    \n",
    "    \n",
    "def create_features(doc):\n",
    "    \"\"\"\n",
    "    Parses a doc and creates a dictionary of features for each token that is not a whitespace.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        # Skip if whitespace\n",
    "        if token.is_space:\n",
    "            continue\n",
    "            \n",
    "        # Get previous and next token\n",
    "        prev_token, next_token = get_neighbors(doc, token.i)\n",
    "\n",
    "        # Create a dict of features\n",
    "        token_features = {\n",
    "                'phrase': token.text,\n",
    "                'start_char': token.idx,\n",
    "                'end_char': token.idx + len(token),\n",
    "                'is_capitilized': token.is_alpha and (token.text[0] == token.text.upper()[0]),\n",
    "                'is_upper': token.is_upper,\n",
    "                'is_lower': token.is_lower,\n",
    "                'prefix1': token.text[:1],\n",
    "                'prefix2': token.text[:2] if len(token)>1 else \"\",\n",
    "                'prefix3': token.text[:3] if len(token)>2 else \"\",\n",
    "                'suffix1': token.text[-1:],\n",
    "                'suffix2': token.text[-2:] if len(token)>1 else \"\",\n",
    "                'suffix3': token.text[-3:] if len(token)>2 else \"\",\n",
    "                'prev_token': prev_token,\n",
    "                'next_token': next_token,\n",
    "                'has_hyphen': '-' in token.text,\n",
    "                'is_alpha': token.is_alpha,\n",
    "                'is_digit': token.is_digit,\n",
    "                'is_sent_start': token.is_sent_start,\n",
    "                'is_sent_end': token.is_sent_end,\n",
    "                'is_punct': token.is_punct,\n",
    "            }\n",
    "        \n",
    "        features.append(token_features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e2c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature map\n",
    "df['token_features'] = df.doc.apply(create_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6697c",
   "metadata": {},
   "source": [
    "### Label concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3557eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(x):\n",
    "    \"\"\"\n",
    "    Assigns categories to gold standard concepts or 0, if a token was not annotated.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for token in x.doc:\n",
    "        # Skip if whitespace\n",
    "        if token.is_space:\n",
    "            continue\n",
    "\n",
    "        # Is there an annotated entity in the same location?\n",
    "        concept = true_concepts_bioes.loc[(true_concepts_bioes.histopathology_id==x.histopathology_id) & \n",
    "                                          (true_concepts_bioes.start_char==token.idx), 'concept'] \n",
    "        \n",
    "        # Assign labels\n",
    "        if concept.empty:\n",
    "            labels.append(\"O\")\n",
    "        else:\n",
    "            labels.append(concept.iloc[0])\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35fa04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 s, sys: 135 ms, total: 26.2 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Labels\n",
    "df['token_labels'] = df.apply(create_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb9e77",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b26d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X = df.order_results\n",
    "# y = df.y\n",
    "# groups = df.patient_id\n",
    "\n",
    "# param_space = {\n",
    "#     'c1': [0.01, 0.1, 1, 10],\n",
    "#     'c2': [0.01, 0.1, 1, 10],\n",
    "# #     'all_possible_states': [False, True],\n",
    "# #     'all_possible_transitions': [False, True],\n",
    "# }\n",
    "\n",
    "# best_params = None\n",
    "# best_score = float('-inf')\n",
    "\n",
    "# for c1 in param_space['c1']:\n",
    "#     for c2 in param_space['c2']:\n",
    "\n",
    "#         cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=3)\n",
    "#         f1_score = []\n",
    "\n",
    "#         for train_idx, val_idx in cv.split(X, y, groups):\n",
    "            \n",
    "#             # Initialise CRF object \n",
    "#             crf = CRF(algorithm='lbfgs', c1=c1, c2=c2)\n",
    "\n",
    "#             # Train the model\n",
    "#             crf.fit(df.loc[train_idx, 'token_features'], df.loc[train_idx, 'token_labels'])\n",
    "\n",
    "#             # Make predictions on the validation fold\n",
    "#             y_pred = crf.predict(df.loc[val_idx, 'token_features'])\n",
    "\n",
    "#             # Calculate macro f1\n",
    "#             f1_score.append(flat_f1_score(df.loc[val_idx, 'token_labels'], y_pred, average='macro'))\n",
    "            \n",
    "#         print(\"With parameters c1=%.2f and c2=%.2f, the model achieves %.2f (+/- %.2f).\" % \n",
    "#               (c1, c2, np.mean(f1_score), np.std(f1_score)))\n",
    "\n",
    "#         if np.mean(f1_score) > best_score:\n",
    "#             best_score = np.mean(f1_score)\n",
    "#             best_params = {'c1': c1, 'c2': c2}\n",
    "                \n",
    "                \n",
    "# print(\"Best macro F1 score = %.2f. Best hyperparameter values: c1=%.2f and c2=%.2f.\" % \n",
    "#       (best_score, best_params['c1'], best_params['c2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88732d9c",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bbf2046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 9s, sys: 1.73 s, total: 5min 11s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = df.order_results\n",
    "y = df.y\n",
    "groups = df.patient_id\n",
    "\n",
    "df['y_pred'] = np.empty((len(df), 0)).tolist()\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=3)\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y, groups):\n",
    "            \n",
    "    # Initialise CRF object \n",
    "    crf = CRF(algorithm='lbfgs', c1=0.01, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "\n",
    "    # Train the model\n",
    "    crf.fit(df.loc[train_idx, 'token_features'], df.loc[train_idx, 'token_labels'])\n",
    "\n",
    "    # Make predictions on the validation fold\n",
    "    df.loc[val_idx, 'y_pred'] = pd.Series(crf.predict(df.loc[val_idx, 'token_features']), \n",
    "                                          index=val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843b766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_concepts_bioes = pd.DataFrame(columns=['histopathology_id', 'patient_id', 'report_no',\n",
    "                                                'concept', 'phrase', 'start_char', 'end_char'])\n",
    "\n",
    "for _,x in df.iterrows(): \n",
    "    \n",
    "    if all(xx=='O' for xx in x):\n",
    "        continue\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    tmp = pd.concat([pd.DataFrame(x.token_features, columns=['phrase', 'start_char', 'end_char']), \n",
    "                     pd.Series(x.y_pred, name='concept')],\n",
    "                    axis=1)\n",
    "    tmp = tmp[tmp.concept!='O']\n",
    "    \n",
    "    # Add metadata\n",
    "    tmp['histopathology_id'] = x.histopathology_id\n",
    "    tmp['patient_id'] = x.patient_id\n",
    "    tmp['report_no'] = x.report_no    \n",
    "    \n",
    "    # Add to the table of detected concepts\n",
    "    detected_concepts_bioes = pd.concat([detected_concepts_bioes, tmp], axis=0, ignore_index=True)   \n",
    "    \n",
    "detected_concepts_bioes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce194e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_concepts = pd.DataFrame(columns=['histopathology_id', 'patient_id', 'report_no',\n",
    "                                          'concept', 'phrase', 'start_char', 'end_char'])\n",
    "\n",
    "for _,x in df.iterrows(): \n",
    "    \n",
    "    if all(xx=='O' for xx in x.y_pred):\n",
    "        continue\n",
    "        \n",
    "    ents = {k:[] for k in ('concept', 'phrase', 'start_char', 'end_char')}\n",
    "\n",
    "    for i,y in enumerate(x.y_pred):\n",
    "        if y==\"O\":\n",
    "            continue\n",
    "        if y.startswith(\"S-\"):\n",
    "            # Record start and end char positions\n",
    "            start_char = x.token_features[i]['start_char']\n",
    "            end_char = x.token_features[i]['end_char']\n",
    "\n",
    "            # Add single-token entity\n",
    "            ents['concept'].append(y[2:])\n",
    "            ents['phrase'].append(x.order_results[start_char:end_char])\n",
    "            ents['start_char'].append(start_char)\n",
    "            ents['end_char'].append(end_char)\n",
    "\n",
    "            # Reset start_char, end_char (optional)\n",
    "            start_char, end_char = None, None\n",
    "\n",
    "        elif y.startswith(\"B-\"):\n",
    "            # Only track a multi-token entity if B is followed by I or E\n",
    "            if x.y_pred[i+1].startswith(\"I-\") or x.y_pred[i+1].startswith(\"E-\"):\n",
    "                # Record start char position\n",
    "                start_char = x.token_features[i]['start_char']\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        elif y.startswith(\"I-\"):\n",
    "            if start_char:\n",
    "                continue\n",
    "            else:\n",
    "                start_char = x.token_features[i]['start_char']\n",
    "\n",
    "        elif y.startswith(\"E-\"):\n",
    "            # Record end char position\n",
    "            end_char = x.token_features[i]['end_char']\n",
    "\n",
    "            # Add multi-token entity\n",
    "            ents['concept'].append(y[2:])\n",
    "            ents['phrase'].append(x.order_results[start_char:end_char])\n",
    "            ents['start_char'].append(start_char)\n",
    "            ents['end_char'].append(end_char)\n",
    "            \n",
    "            # Reset start_char, end_char (optional)\n",
    "            start_char, end_char = None, None\n",
    "\n",
    "    # Convert to dataframe    \n",
    "    tmp = pd.DataFrame(ents)\n",
    "    \n",
    "    # Add metadata\n",
    "    tmp['histopathology_id'] = x.histopathology_id\n",
    "    tmp['patient_id'] = x.patient_id\n",
    "    tmp['report_no'] = x.report_no\n",
    "    \n",
    "    # Add to the table of detected concepts\n",
    "    detected_concepts = pd.concat([detected_concepts, tmp], axis=0, ignore_index=True)   \n",
    "    \n",
    "detected_concepts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa281e",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed66a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    mean   std\n",
      "concept                       \n",
      "B-ClinicalQuery     0.86  0.21\n",
      "I-ClinicalQuery     0.60  0.27\n",
      "E-ClinicalQuery     0.77  0.28\n",
      "S-ClinicalQuery     0.50  0.71\n",
      "B-FungalDescriptor  0.87  0.09\n",
      "I-FungalDescriptor  0.83  0.41\n",
      "E-FungalDescriptor  0.92  0.07\n",
      "S-FungalDescriptor  0.81  0.18\n",
      "B-Fungus            1.00  0.00\n",
      "I-Fungus             NaN   NaN\n",
      "E-Fungus            1.00  0.00\n",
      "S-Fungus            0.97  0.07\n",
      "B-Invasiveness      0.50  0.71\n",
      "I-Invasiveness      0.33  0.58\n",
      "E-Invasiveness      0.67  0.58\n",
      "S-Invasiveness       NaN   NaN\n",
      "B-Stain             1.00   NaN\n",
      "I-Stain              NaN   NaN\n",
      "E-Stain             1.00   NaN\n",
      "S-Stain             0.92  0.08\n",
      "B-SampleType        0.68  0.31\n",
      "I-SampleType         NaN   NaN\n",
      "E-SampleType        0.68  0.31\n",
      "S-SampleType        0.59  0.20\n",
      "B-positive          1.00  0.00\n",
      "I-positive           NaN   NaN\n",
      "E-positive          1.00  0.00\n",
      "S-positive          0.62  0.44\n",
      "B-equivocal          NaN   NaN\n",
      "I-equivocal          NaN   NaN\n",
      "E-equivocal          NaN   NaN\n",
      "S-equivocal          NaN   NaN\n",
      "B-negative          1.00   NaN\n",
      "I-negative           NaN   NaN\n",
      "E-negative          1.00   NaN\n",
      "S-negative          0.88  0.10\n",
      "                    mean   std\n",
      "concept                       \n",
      "B-ClinicalQuery     0.75  0.26\n",
      "I-ClinicalQuery     0.29  0.37\n",
      "E-ClinicalQuery     0.67  0.28\n",
      "S-ClinicalQuery     0.13  0.30\n",
      "B-FungalDescriptor  0.75  0.15\n",
      "I-FungalDescriptor  0.36  0.35\n",
      "E-FungalDescriptor  0.80  0.11\n",
      "S-FungalDescriptor  0.68  0.24\n",
      "B-Fungus            0.92  0.14\n",
      "I-Fungus             NaN   NaN\n",
      "E-Fungus            0.92  0.14\n",
      "S-Fungus            0.79  0.22\n",
      "B-Invasiveness      0.08  0.20\n",
      "I-Invasiveness      0.08  0.14\n",
      "E-Invasiveness      0.17  0.26\n",
      "S-Invasiveness      0.00  0.00\n",
      "B-Stain             0.08  0.20\n",
      "I-Stain             0.00  0.00\n",
      "E-Stain             0.08  0.20\n",
      "S-Stain             0.94  0.09\n",
      "B-SampleType        0.37  0.38\n",
      "I-SampleType        0.00  0.00\n",
      "E-SampleType        0.37  0.38\n",
      "S-SampleType        0.24  0.11\n",
      "B-positive          0.37  0.46\n",
      "I-positive          0.00  0.00\n",
      "E-positive          0.37  0.46\n",
      "S-positive          0.12  0.16\n",
      "B-equivocal          NaN   NaN\n",
      "I-equivocal          NaN   NaN\n",
      "E-equivocal          NaN   NaN\n",
      "S-equivocal         0.00  0.00\n",
      "B-negative          0.03  0.09\n",
      "I-negative          0.00  0.00\n",
      "E-negative          0.03  0.09\n",
      "S-negative          0.69  0.11\n"
     ]
    }
   ],
   "source": [
    "feature_names = evalutils.get_feature_names('concepts', ('B-', 'I-', 'E-', 'S-'))\n",
    "evalutils.evaluate_ner_cv(df[['histopathology_id', 'val_fold']], \n",
    "                          true_concepts_bioes, \n",
    "                          detected_concepts_bioes, \n",
    "                          feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c1d3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(feature_set, tags=None):\n",
    "    \"\"\"\n",
    "    Return the list of concepts, relations, or composite concepts.\n",
    "    \"\"\"\n",
    "    if feature_set=='concepts':\n",
    "        feature_names = ['ClinicalQuery', 'FungalDescriptor', 'Fungus', 'Invasiveness', 'Stain', 'SampleType', \n",
    "                'positive', 'equivocal', 'negative']\n",
    "    elif feature_set=='relations':\n",
    "        feature_names = ['positive-rel', 'equivocal-rel', 'negative-rel', \n",
    "                'fungal-description-rel', 'invasiveness-rel', 'fungus-stain-rel']\n",
    "    elif feature_set=='composite':\n",
    "        feature_names = ['affirmedFungalDescriptor', 'affirmedFungus', 'affirmedInvasiveness', 'affirmedStain',\n",
    "                'negatedFungalDescriptor', 'negatedFungus', 'negatedInvasiveness', 'negatedStain']\n",
    "    elif feature_set=='termsets':\n",
    "        feature_names = ['preceding_positive', 'following_positive', 'preceding_negative', 'following_negative']\n",
    "    \n",
    "    if tags:\n",
    "        return [tag + ft for ft in feature_names for tag in [\"B-\", \"I-\", \"E-\", \"S-\"]]\n",
    "    else:\n",
    "        return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32c1a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mean   std\n",
      "concept                     \n",
      "ClinicalQuery     0.98  0.08\n",
      "FungalDescriptor  0.93  0.06\n",
      "Fungus            0.98  0.05\n",
      "Invasiveness      0.67  0.58\n",
      "Stain             0.96  0.06\n",
      "SampleType        0.59  0.14\n",
      "positive          0.73  0.37\n",
      "equivocal          NaN   NaN\n",
      "negative          0.89  0.09\n",
      "                  mean   std\n",
      "concept                     \n",
      "ClinicalQuery     0.72  0.22\n",
      "FungalDescriptor  0.80  0.11\n",
      "Fungus            0.80  0.21\n",
      "Invasiveness      0.13  0.21\n",
      "Stain             0.92  0.09\n",
      "SampleType        0.26  0.11\n",
      "positive          0.20  0.21\n",
      "equivocal         0.00  0.00\n",
      "negative          0.58  0.12\n"
     ]
    }
   ],
   "source": [
    "feature_names = get_feature_names('concepts')\n",
    "evalutils.evaluate_ner_cv(df[['histopathology_id', 'val_fold']], true_concepts, detected_concepts, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20527ae",
   "metadata": {},
   "source": [
    "### Plot comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Pretty plots\n",
    "%matplotlib inline\n",
    "sns.set_style('ticks')\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.title_fontsize'] = 12\n",
    "\n",
    "# Display wide columns\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names('concepts')\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary-based precision\n",
    "dict_prec_mean = [0.92, 0.75, 0.82, 0.45, 0.94, 0.15, 0.04, 0.01, 0.14]\n",
    "dict_prec_std = [0.13, 0.1, 0.3, 0.41, 0.05, 0.03, 0.02, 0.02, 0.04]\n",
    "\n",
    "# Dictionary-based recall\n",
    "dict_rec_mean = [0.53, 0.93, 0.92, 0.60, 0.95, 0.86, 0.83, 0.58, 0.98]\n",
    "dict_rec_std = [0.35, 0.04, 0.15, 0.39, 0.09, 0.1, 0.17, 0.5, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'feature_names': feature_names, \n",
    "                       'dict_prec_mean': dict_prec_mean, \n",
    "                       'dict_prec_std': dict_prec_std, \n",
    "                       'crf_prec_mean': crf_prec_mean, \n",
    "                       'crf_prec_std': crf_prec_std, \n",
    "                       'dict_rec_mean': dict_rec_mean, \n",
    "                       'dict_rec_std': dict_rec_std, \n",
    "                       'crf_rec_mean': crf_rec_mean, \n",
    "                       'crf_rec_std': crf_rec_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "\n",
    "colors = (sns.color_palette()[0], sns.color_palette()[3])\n",
    "\n",
    "# Dictionary-based approach\n",
    "plt.errorbar(x=scores.feature_names, y=scores.dict_prec_mean, yerr=scores.dict_prec_std, \n",
    "             fmt='o', capsize=2, color=colors[0], label=\"Dictionary\")\n",
    "\n",
    "# CRF\n",
    "plt.errorbar(x=scores.feature_names, y=scores.crf_prec_mean, yerr=scores.crf_prec_std, \n",
    "             fmt='o', capsize=2, color=colors[1], label=\"CRF\")\n",
    "\n",
    "plt.legend();\n",
    "plt.xticks(rotation=90);\n",
    "plt.title(\"Precision CV\");\n",
    "plt.ylim([-0.2, 1.5])\n",
    "\n",
    "plt.savefig(\"comparison_precision_cv\", dpi=300, bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "\n",
    "colors = (sns.color_palette()[0], sns.color_palette()[3])\n",
    "\n",
    "# Dictionary-based approach\n",
    "plt.errorbar(x=scores.feature_names, y=scores.dict_rec_mean, yerr=scores.dict_rec_std, \n",
    "             fmt='o', capsize=2, color=colors[0], label=\"Dictionary\")\n",
    "\n",
    "# CRF\n",
    "plt.errorbar(x=scores.feature_names, y=scores.crf_rec_mean, yerr=scores.crf_rec_std, \n",
    "             fmt='o', capsize=2, color=colors[1], label=\"CRF\")\n",
    "\n",
    "plt.legend();\n",
    "plt.xticks(rotation=90);\n",
    "plt.title(\"Recall CV\");\n",
    "plt.ylim([-0.2, 1.5]);\n",
    "\n",
    "plt.savefig(\"comparison_recall_cv\", dpi=300, bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
